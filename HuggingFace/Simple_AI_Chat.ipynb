{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!pip install openai"
      ],
      "metadata": {
        "id": "dG1nQOVHshLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"...\""
      ],
      "metadata": {
        "id": "HVAroVpPoS2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=os.environ['GOOGLE_API_KEY'],\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/\"\n",
        ")"
      ],
      "metadata": {
        "id": "pCnl0TGioY2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    messages=[\n",
        "\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Explain how AI works in simple terms.\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "print(response.choices[0].message.content)\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqtf_PNXq_0z",
        "outputId": "7a833f9c-69f9-4363-dd45-cdab028fc7ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imagine teaching a dog a trick.  You show it what to do, reward it when it's right, and correct it when it's wrong.  Over time, the dog learns.\n",
            "\n",
            "AI is similar.  We \"train\" computers by showing them lots of examples.  For example, to recognize a cat, we show it thousands of pictures of cats, labeling each one \"cat.\"  The computer learns patterns in those pictures – pointy ears, whiskers, furry texture – and eventually it can identify a cat in a new picture it's never seen before.\n",
            "\n",
            "This learning happens through complex math and algorithms (like a secret recipe), but the basic idea is simple: show the computer lots of examples, and it learns to recognize patterns and make predictions.\n",
            "\n",
            "Different types of AI do different things: some play chess, some translate languages, some drive cars.  But they all rely on this fundamental principle of learning from examples.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_response(prompt):\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gemini-1.5-flash\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "        ,\n",
        "        max_tokens=100 ,\n",
        "        temperature=0\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# Test the function\n",
        "response = get_response(\"Explain what prompt engineering mean ? \")\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmC7ET17sDOV",
        "outputId": "c321186f-ec2b-4c7d-f22e-4505f095bb2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt engineering is the process of designing and crafting effective prompts to elicit desired outputs from language models (like ChatGPT, Bard, etc.) or other AI systems.  It's about understanding how to communicate your needs clearly and concisely to the AI so it generates the most relevant, accurate, and creative responses.\n",
            "\n",
            "Think of it like this: you're not just asking a question; you're carefully constructing a request that guides the AI's reasoning and generation process.  A poorly written\n"
          ]
        }
      ]
    }
  ]
}
